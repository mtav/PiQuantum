* Operators
** Single qubit gates
*** 2nd March 2019
Added single qubit gates. For a 20 qubit state vector, applying H to all 20 qubits 20 times takes 9.15s. So each single qubit gate takes 0.023s.

Tested the sgate routine without a function body (incrementing a private class member variable bench to stop it optimising the loops away). The same 20 loops of 20 tests takes 0.6s (0.0015s per operation) indicating that the for loops don't add very much overhead (unless the compiler is still finding a way to 
remove/simplify them).
 
Aligning the state vector doesn't make any substantial difference to single qubit gate times.

Splitting the functions up into seperate source files (so that they end up in different translation units) slows down the single qubit gate times a bit -- to 13.5s for 20 rounds of 20 qubit operations, corresponding to 0.033s per single qubit operation. Adding link time optimisation (-flto) gets the time back down to before. Adding -march=native and -O3 makes no difference to the times

*** 3rd March 2019
Disassembled the single qubit gate function. The top level (sgate) comprises 28 instructions, one of which is a call to cmatvec which comprises 43 instructions. All the cadds and cmuls have been inlined.

It doesn't slow things down adding threading overhead (checking for joinable) in the cmatvec function. Bizarrely it actually seems to speed up the sgate function. Starting a thread in the cmatvec function is horrendously slow (10s of seconds per single qubit gate).

Using a common thread to do the writing isn't as bad as before but is still much slower (probably an order of magnitude) than just doing the writing as before.
 
** Controlled gates
*** 2nd March 2019
Controlled gates also seem to take a similar time to single qubit gates which is confusing since they have half the matrix multiplications. The time for 20 runs of 20 controlled H operations is 8.83s corresponding to 0.022s per controlled gate. Using X instead of H makes basically no difference. Inlining the matrix multiplication and removing print statements makes no difference. (-O2 was probably inlining anyway, and there weren't very many print statements)

The same for loop overhead test as above (incrementing a private member variable in the for loop) for 20 loops of 20 qubits took 0.36s in total (about 0.00075s) per loop, about half of the time for a single qubit operation. That makes since since there are half as many evaluations of the inner for loop body for the controlled gate case compared to the single qubit gate case.  

Re running the proper controlled and single qubit gate tests shows that the single qubit gates do take a bit longer than control qubit gates (not double). There might be other effects at play (caching etc.) that behave differently in the two cases that accounts for the difference in speed.

*** 3rd March 2019
Disassembled the controlled qubit gate function. It seems to have inlined the whole of the cgate function.

** Display averaging
*** 2nd March 2019
100 state averages of 20 qubits takes 14.3s, so 0.14s per average. To be honest this is still quite slow -- you can see the operation happen. Removing the dynamic cache allocation from the function does not make a difference (not surprising since there was only one, but still an improvement).

Adding arctan caching on the first qubit only significantly slows down the function. Now 100 averages of 20 qubits takes 28s, which is 0.28s per average. That's long enough to be easily noticeable. 
